{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-27T21:44:03.003477461Z",
     "start_time": "2026-01-27T21:36:05.588759031Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Generisches DL Model zum Einlesen der Modelle\n",
    "class GenericModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_layers, activation=\"relu\", dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "\n",
    "        act = {\n",
    "            \"relu\": nn.ReLU,\n",
    "            \"tanh\": nn.Tanh,\n",
    "            \"sigmoid\": nn.Sigmoid\n",
    "        }[activation]\n",
    "\n",
    "        for h in hidden_layers:\n",
    "            layers.append(nn.Linear(in_dim, h))\n",
    "            layers.append(act())\n",
    "            if dropout > 0:\n",
    "                layers.append(nn.Dropout(dropout))\n",
    "            in_dim = h\n",
    "\n",
    "        layers.append(nn.Linear(in_dim, output_dim))\n",
    "\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "#Gewichtete Loss Funktion\n",
    "class WeightedMSELoss(nn.Module):\n",
    "    def __init__(self, weights):\n",
    "        super().__init__()\n",
    "        self.weights = torch.tensor(weights)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        loss = (pred - target) ** 2\n",
    "        loss = loss * self.weights\n",
    "        return loss.mean()\n",
    "\n",
    "#Optimizer Auswahlfunktion\n",
    "def make_optimizer(model, name, params):\n",
    "    name = name.lower()\n",
    "\n",
    "    if name == \"adam\":\n",
    "        return optim.Adam(model.parameters(), **params)\n",
    "    elif name == \"adamw\":\n",
    "        return optim.AdamW(model.parameters(), **params)\n",
    "    elif name == \"sgd\":\n",
    "        return optim.SGD(model.parameters(), **params)\n",
    "    elif name == \"radam\":\n",
    "        return torch.optim.RAdam(model.parameters(), **params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {name}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Dateipfad initialisieren\n",
    "#Project root (assumes notebook is in /notebooks)\n",
    "ROOT = Path.cwd().resolve().parents[0]\n",
    "sys.path.insert(0, str(ROOT))\n",
    "\n",
    "#Dateipfad\n",
    "data_path = ROOT / \"data\" / \"processed\"\n",
    "\n",
    "#Trainingsdaten lesen\n",
    "data = np.load(os.path.join(data_path, \"data_for_training.npz\"))\n",
    "\n",
    "X_raw  = data[\"X\"]        # für Split nach Polaren\n",
    "X = torch.tensor(data[\"X_norm\"], dtype=torch.float32)\n",
    "Y = torch.tensor(data[\"Y_norm\"], dtype=torch.float32)\n",
    "\n",
    "print(f\"Loaded data: X {X.shape}, Y {Y.shape}\")\n",
    "\n",
    "#Modelle einlesen\n",
    "model_info = np.load(os.path.join(data_path,\"model_info.npy\"), allow_pickle=True).item()\n",
    "\n",
    "models = {}\n",
    "\n",
    "for name, cfg in model_info.items():\n",
    "    model = GenericModel(\n",
    "        input_dim=cfg[\"input_dim\"],\n",
    "        output_dim=cfg[\"output_dim\"],\n",
    "        hidden_layers=cfg[\"layers\"],\n",
    "        activation=cfg[\"activation\"],\n",
    "        dropout=cfg[\"dropout\"]\n",
    "    )\n",
    "    models[name] = model\n",
    "\n",
    "#Trainingsparameter\n",
    "epochs = 1000\n",
    "batch_size = 256\n",
    "optimizer_name = \"radam\"      # \"sgd\", \"radam\", \"adamw\" oder \"adam\"    Dank obiger Funktion erweiterbar\n",
    "optimizer_params = {        # learningrate und weight decay\n",
    "    \"lr\": 3e-4,\n",
    "    #\"momentum\": 0.9,   #Momentum NUR für SGD, wenn gewollt\n",
    "    #\"nesterov\": True,  #Nesterov Momentum(NAG) NUR für SGD mit Momentum: \"Vorausschauendes Momentum\", wenn gewollt\n",
    "    \"weight_decay\": 5e-5\n",
    "}\n",
    "\n",
    "loss_weights = [1.0, 2.0, 0.2, 0.2]  # CL, CD, Top_Xtr, Bot_Xtr\n",
    "criterion = WeightedMSELoss(loss_weights)   #gewichtete Loss Funktion\n",
    "#criterion = nn.MSELoss()   #ungewichtete Loss Funktion\n",
    "\n",
    "split = \"group\"    #\"random\" oder \"group\"  Zufälliger Split oder Split nach Polaren\n",
    "train_ratio = 0.8\n",
    "\n",
    "#Zufälliger Split\n",
    "if split == \"random\":\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    indices = torch.randperm(num_samples)\n",
    "    train_size = int(train_ratio * num_samples)\n",
    "\n",
    "    train_idx = indices[:train_size]\n",
    "    val_idx   = indices[train_size:]\n",
    "\n",
    "    X_train, Y_train = X[train_idx], Y[train_idx]\n",
    "    X_val,   Y_val   = X[val_idx],   Y[val_idx]\n",
    "\n",
    "    print(f\"Train samples: {X_train.shape[0]}\")\n",
    "    print(f\"Val samples  : {X_val.shape[0]}\")\n",
    "\n",
    "#Split nach Polaren\n",
    "elif split == \"group\":\n",
    "    groups = np.array([\n",
    "    f\"{int(x[0])}_{int(x[1])}_{x[2]:.3f}\" for x in X_raw\n",
    "    ])\n",
    "\n",
    "    unique_groups = np.unique(groups)\n",
    "    np.random.shuffle(unique_groups)\n",
    "\n",
    "    n_train_groups = int(train_ratio * len(unique_groups))\n",
    "\n",
    "    train_groups = set(unique_groups[:n_train_groups])\n",
    "    val_groups   = set(unique_groups[n_train_groups:])\n",
    "\n",
    "    train_idx = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "    val_idx   = [i for i, g in enumerate(groups) if g in val_groups]\n",
    "\n",
    "    X_train = X[train_idx]\n",
    "    Y_train = Y[train_idx]\n",
    "    X_val   = X[val_idx]\n",
    "    Y_val   = Y[val_idx]\n",
    "\n",
    "    print(f\"Train samples: {len(train_idx)}\")\n",
    "    print(f\"Val samples  : {len(val_idx)}\")\n",
    "\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown split: {split}\")\n",
    "\n",
    "#DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_train, Y_train),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    torch.utils.data.TensorDataset(X_val, Y_val),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "#Training\n",
    "save_dir = os.path.join(data_path, \"trained_models\")\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining model: {name}\\nOptimizer: {optimizer_name}\")\n",
    "\n",
    "    optimizer = make_optimizer(model, optimizer_name, optimizer_params)\n",
    "\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses=[]\n",
    "    best_val_loss = float(\"inf\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        #Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(xb)\n",
    "            loss = criterion(y_pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        #Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                pred = model(xb)\n",
    "                loss = criterion(pred, yb)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(\n",
    "                f\"Epoch {epoch+1:4d} | \"\n",
    "                f\"Train: {train_loss:.4e} | \"\n",
    "                f\"Val: {val_loss:.4e}\"\n",
    "            )\n",
    "\n",
    "        #   Gewichte der besten Epoche speichern\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(save_dir, f\"{name}_best.pth\")\n",
    "            )\n",
    "\n",
    "    #   Endgewichte speichern\n",
    "    torch.save(\n",
    "        model.state_dict(),\n",
    "        os.path.join(save_dir, f\"{name}_weights.pth\")\n",
    "    )\n",
    "\n",
    "    #training Plots generieren und speichern\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(val_losses, label=\"Validation\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"{name} loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, f\"{name}_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    print(f\"✓ Best val loss for {name}: {best_val_loss:.4e}\")\n",
    "    print(f\"✓ Saved weights for {name}\")\n",
    "\n",
    "#Beispielcode fürs spätere Laden:\n",
    "#model = models[medium]    #hier das rekonstruiere Model angeben\n",
    "#model.load_state_dict(torch.load(\"medium_weights.pth\"))\n",
    "#model.eval()'''\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data: X torch.Size([21818, 4]), Y torch.Size([21818, 4])\n",
      "Train samples: 17491\n",
      "Val samples  : 4327\n",
      "\n",
      "Training model: small\n",
      "Optimizer: radam\n",
      "Epoch   50 | Train: 2.4307e-01 | Val: 2.4731e-01\n",
      "Epoch  100 | Train: 2.1013e-01 | Val: 2.0941e-01\n",
      "Epoch  150 | Train: 2.0059e-01 | Val: 1.9450e-01\n",
      "Epoch  200 | Train: 1.8820e-01 | Val: 1.8461e-01\n",
      "Epoch  250 | Train: 1.8155e-01 | Val: 1.7655e-01\n",
      "Epoch  300 | Train: 1.7411e-01 | Val: 1.6785e-01\n",
      "Epoch  350 | Train: 1.6906e-01 | Val: 1.6076e-01\n",
      "Epoch  400 | Train: 1.6317e-01 | Val: 1.5440e-01\n",
      "Epoch  450 | Train: 1.5899e-01 | Val: 1.4906e-01\n",
      "Epoch  500 | Train: 1.5492e-01 | Val: 1.4370e-01\n",
      "Epoch  550 | Train: 1.5053e-01 | Val: 1.3878e-01\n",
      "Epoch  600 | Train: 1.4672e-01 | Val: 1.3418e-01\n",
      "Epoch  650 | Train: 1.4330e-01 | Val: 1.3014e-01\n",
      "Epoch  700 | Train: 1.4099e-01 | Val: 1.2651e-01\n",
      "Epoch  750 | Train: 1.3707e-01 | Val: 1.2339e-01\n",
      "Epoch  800 | Train: 1.3541e-01 | Val: 1.1960e-01\n",
      "Epoch  850 | Train: 1.3238e-01 | Val: 1.1684e-01\n",
      "Epoch  900 | Train: 1.2942e-01 | Val: 1.1348e-01\n",
      "Epoch  950 | Train: 1.2731e-01 | Val: 1.1137e-01\n",
      "Epoch 1000 | Train: 1.2508e-01 | Val: 1.0812e-01\n",
      "✓ Best val loss for small: 1.0810e-01\n",
      "✓ Saved weights for small\n",
      "\n",
      "Training model: medium\n",
      "Optimizer: radam\n",
      "Epoch   50 | Train: 1.7628e-01 | Val: 1.7401e-01\n",
      "Epoch  100 | Train: 1.3439e-01 | Val: 1.2512e-01\n",
      "Epoch  150 | Train: 1.0879e-01 | Val: 1.0264e-01\n",
      "Epoch  200 | Train: 9.0531e-02 | Val: 8.8671e-02\n",
      "Epoch  250 | Train: 7.7755e-02 | Val: 8.5399e-02\n",
      "Epoch  300 | Train: 6.8343e-02 | Val: 7.5473e-02\n",
      "Epoch  350 | Train: 6.2844e-02 | Val: 7.4583e-02\n",
      "Epoch  400 | Train: 5.9996e-02 | Val: 7.4806e-02\n",
      "Epoch  450 | Train: 5.7273e-02 | Val: 7.1821e-02\n",
      "Epoch  500 | Train: 5.5812e-02 | Val: 7.4730e-02\n",
      "Epoch  550 | Train: 5.4779e-02 | Val: 7.4169e-02\n",
      "Epoch  600 | Train: 5.3493e-02 | Val: 7.4839e-02\n",
      "Epoch  650 | Train: 5.3107e-02 | Val: 7.7138e-02\n",
      "Epoch  700 | Train: 5.2265e-02 | Val: 7.8027e-02\n",
      "Epoch  750 | Train: 5.1494e-02 | Val: 7.9231e-02\n",
      "Epoch  800 | Train: 5.0788e-02 | Val: 7.9179e-02\n",
      "Epoch  850 | Train: 5.0192e-02 | Val: 8.1309e-02\n",
      "Epoch  900 | Train: 4.9663e-02 | Val: 8.1296e-02\n",
      "Epoch  950 | Train: 4.9151e-02 | Val: 8.6255e-02\n",
      "Epoch 1000 | Train: 4.8689e-02 | Val: 8.4868e-02\n",
      "✓ Best val loss for medium: 7.0638e-02\n",
      "✓ Saved weights for medium\n",
      "\n",
      "Training model: deep\n",
      "Optimizer: radam\n",
      "Epoch   50 | Train: 1.0094e-01 | Val: 8.0885e-02\n",
      "Epoch  100 | Train: 6.3515e-02 | Val: 7.2805e-02\n",
      "Epoch  150 | Train: 5.7517e-02 | Val: 6.9326e-02\n",
      "Epoch  200 | Train: 5.5501e-02 | Val: 7.0458e-02\n",
      "Epoch  250 | Train: 5.1819e-02 | Val: 7.8775e-02\n",
      "Epoch  300 | Train: 4.6882e-02 | Val: 7.8723e-02\n",
      "Epoch  350 | Train: 4.3955e-02 | Val: 8.8490e-02\n",
      "Epoch  400 | Train: 4.0724e-02 | Val: 9.2708e-02\n",
      "Epoch  450 | Train: 3.8392e-02 | Val: 9.4399e-02\n",
      "Epoch  500 | Train: 3.7104e-02 | Val: 1.0337e-01\n",
      "Epoch  550 | Train: 3.5020e-02 | Val: 1.0157e-01\n",
      "Epoch  600 | Train: 3.3754e-02 | Val: 9.8654e-02\n",
      "Epoch  650 | Train: 3.2801e-02 | Val: 1.0464e-01\n",
      "Epoch  700 | Train: 3.1004e-02 | Val: 1.0728e-01\n",
      "Epoch  750 | Train: 3.0523e-02 | Val: 1.0824e-01\n",
      "Epoch  800 | Train: 2.9415e-02 | Val: 1.0979e-01\n",
      "Epoch  850 | Train: 2.7736e-02 | Val: 1.1684e-01\n",
      "Epoch  900 | Train: 2.7626e-02 | Val: 1.1505e-01\n",
      "Epoch  950 | Train: 2.6387e-02 | Val: 1.1405e-01\n",
      "Epoch 1000 | Train: 2.5958e-02 | Val: 1.1347e-01\n",
      "✓ Best val loss for deep: 6.3688e-02\n",
      "✓ Saved weights for deep\n",
      "\n",
      "Training model: dropout\n",
      "Optimizer: radam\n",
      "Epoch   50 | Train: 2.2730e-01 | Val: 1.8976e-01\n",
      "Epoch  100 | Train: 1.8804e-01 | Val: 1.3582e-01\n",
      "Epoch  150 | Train: 1.5599e-01 | Val: 1.0672e-01\n",
      "Epoch  200 | Train: 1.2639e-01 | Val: 8.9134e-02\n",
      "Epoch  250 | Train: 1.3536e-01 | Val: 7.8637e-02\n",
      "Epoch  300 | Train: 1.0682e-01 | Val: 7.1590e-02\n",
      "Epoch  350 | Train: 1.0801e-01 | Val: 7.1738e-02\n",
      "Epoch  400 | Train: 1.1429e-01 | Val: 6.4574e-02\n",
      "Epoch  450 | Train: 1.1922e-01 | Val: 6.3370e-02\n",
      "Epoch  500 | Train: 1.0456e-01 | Val: 6.6947e-02\n",
      "Epoch  550 | Train: 1.0135e-01 | Val: 6.3120e-02\n",
      "Epoch  600 | Train: 1.0127e-01 | Val: 6.3893e-02\n",
      "Epoch  650 | Train: 9.7531e-02 | Val: 6.2501e-02\n",
      "Epoch  700 | Train: 9.4763e-02 | Val: 6.5676e-02\n",
      "Epoch  750 | Train: 9.6161e-02 | Val: 7.1484e-02\n",
      "Epoch  800 | Train: 9.9537e-02 | Val: 6.4675e-02\n",
      "Epoch  850 | Train: 9.4721e-02 | Val: 6.7769e-02\n",
      "Epoch  900 | Train: 9.8666e-02 | Val: 6.5648e-02\n",
      "Epoch  950 | Train: 9.4222e-02 | Val: 6.5672e-02\n",
      "Epoch 1000 | Train: 9.2713e-02 | Val: 7.3916e-02\n",
      "✓ Best val loss for dropout: 5.9525e-02\n",
      "✓ Saved weights for dropout\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
